{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patch Based Segmentation of Fundus Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image names\n",
    "import os\n",
    "import os.path\n",
    "import cv2\n",
    "\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.feature_extraction import image as imgutil\n",
    "\n",
    "import time\n",
    "import torch.utils.data as utils\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha, (float, int)): self.alpha = torch.Tensor([alpha, 1 - alpha])\n",
    "        if isinstance(alpha, list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.view(input.size(0), input.size(1), -1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1, 2)                         # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1, input.size(2))    # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1, 1)\n",
    "\n",
    "        logpt = F.log_softmax(input, dim=1)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = logpt.exp()\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type() != input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0, target.data.view(-1))\n",
    "            logpt = logpt * at\n",
    "\n",
    "        loss = -1 * (1 - pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiClassClassifier, self).__init__()\n",
    "        self.conv = nn.Sequential()\n",
    "        self.conv.add_module(\"Pad1\", nn.ConstantPad2d((0,1,0,1), 0))\n",
    "        self.conv.add_module(\"Conv1\", nn.Conv2d(3, 32, kernel_size=2))\n",
    "        self.conv.add_module(\"BN1\", nn.BatchNorm2d(32))\n",
    "        self.conv.add_module(\"Relu1\", nn.ReLU())\n",
    "        \n",
    "        self.conv.add_module(\"Pad2\", nn.ConstantPad2d((0,1,0,1), 0))\n",
    "        self.conv.add_module(\"Conv2\", nn.Conv2d(32, 32, kernel_size=2))\n",
    "        self.conv.add_module(\"BN2\", nn.BatchNorm2d(32))\n",
    "        self.conv.add_module(\"Relu2\", nn.ReLU())\n",
    "        self.conv.add_module(\"Layer2MaxPool\", nn.MaxPool2d(2))\n",
    "        \n",
    "        self.conv.add_module(\"Pad3\", nn.ConstantPad2d((0,1,0,1), 0))\n",
    "        self.conv.add_module(\"Conv3\", nn.Conv2d(32, 64, kernel_size=2))\n",
    "        self.conv.add_module(\"BN3\", nn.BatchNorm2d(64))\n",
    "        self.conv.add_module(\"Relu3\", nn.ReLU())\n",
    "        \n",
    "        self.conv.add_module(\"Pad4\", nn.ConstantPad2d((0,1,0,1), 0))\n",
    "        self.conv.add_module(\"Conv4\", nn.Conv2d(64, 64, kernel_size=2))\n",
    "        self.conv.add_module(\"BN4\", nn.BatchNorm2d(64))\n",
    "        self.conv.add_module(\"Relu4\", nn.ReLU())\n",
    "        self.conv.add_module(\"Layer4MaxPool\", nn.MaxPool2d(2))\n",
    "                             \n",
    "        self.conv.add_module(\"Pad5\", nn.ConstantPad2d((0,1,0,1), 0))\n",
    "        self.conv.add_module(\"Conv5\", nn.Conv2d(64, 128, kernel_size=2))\n",
    "        self.conv.add_module(\"BN5\", nn.BatchNorm2d(128))\n",
    "        self.conv.add_module(\"Relu5\", nn.ReLU())\n",
    "        \n",
    "        self.conv.add_module(\"Pad6\", nn.ConstantPad2d((0,1,0,1), 0))\n",
    "        self.conv.add_module(\"Conv6\", nn.Conv2d(128, 128, kernel_size=2))\n",
    "        self.conv.add_module(\"BN6\", nn.BatchNorm2d(128))\n",
    "        self.conv.add_module(\"Relu6\", nn.ReLU())\n",
    "        self.conv.add_module(\"Layer6MaxPool\", nn.MaxPool2d(2))\n",
    "        \n",
    "        self.conv.add_module(\"Pad7\", nn.ConstantPad2d((0,1,0,1), 0))\n",
    "        self.conv.add_module(\"Conv7\", nn.Conv2d(128, 256, kernel_size=2))\n",
    "        self.conv.add_module(\"BN7\", nn.BatchNorm2d(256))\n",
    "        self.conv.add_module(\"Relu7\", nn.ReLU())\n",
    "        \n",
    "        self.conv.add_module(\"Pad8\", nn.ConstantPad2d((0,1,0,1), 0))\n",
    "        self.conv.add_module(\"Conv8\", nn.Conv2d(256, 256, kernel_size=2))\n",
    "        self.conv.add_module(\"BN8\", nn.BatchNorm2d(256))\n",
    "        self.conv.add_module(\"Relu8\", nn.ReLU())\n",
    "        \n",
    "        self.fc = nn.Sequential()\n",
    "        self.fc.add_module(\"FC1\", nn.Linear(4096, 1000))\n",
    "        self.fc.add_module(\"Relu9\", nn.ReLU())\n",
    "        self.fc.add_module(\"Dropout1\", nn.Dropout(0.5))\n",
    "        self.fc.add_module(\"FC2\", nn.Linear(1000, 100))\n",
    "        self.fc.add_module(\"Relu10\", nn.ReLU())\n",
    "        self.fc.add_module(\"Dropout1\", nn.Dropout(0.5))\n",
    "        self.fc.add_module(\"FC3\",nn.Linear(100, 5)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.conv = nn.Sequential()\n",
    "        self.conv.add_module(\"Pad1\", nn.ConstantPad2d((0,1,0,1), 0))\n",
    "        self.conv.add_module(\"Conv1\", nn.Conv2d(3, 32, kernel_size=2))\n",
    "        self.conv.add_module(\"BN1\", nn.BatchNorm2d(32))\n",
    "        self.conv.add_module(\"Relu1\", nn.ReLU())\n",
    "        \n",
    "        self.conv.add_module(\"Pad2\", nn.ConstantPad2d((0,1,0,1), 0))\n",
    "        self.conv.add_module(\"Conv2\", nn.Conv2d(32, 32, kernel_size=2))\n",
    "        self.conv.add_module(\"BN2\", nn.BatchNorm2d(32))\n",
    "        self.conv.add_module(\"Relu2\", nn.ReLU())\n",
    "        self.conv.add_module(\"Layer2MaxPool\", nn.MaxPool2d(2))\n",
    "        \n",
    "        self.conv.add_module(\"Pad3\", nn.ConstantPad2d((0,1,0,1), 0))\n",
    "        self.conv.add_module(\"Conv3\", nn.Conv2d(32, 64, kernel_size=2))\n",
    "        self.conv.add_module(\"BN3\", nn.BatchNorm2d(64))\n",
    "        self.conv.add_module(\"Relu3\", nn.ReLU())\n",
    "        \n",
    "        self.conv.add_module(\"Pad4\", nn.ConstantPad2d((0,1,0,1), 0))\n",
    "        self.conv.add_module(\"Conv4\", nn.Conv2d(64, 64, kernel_size=2))\n",
    "        self.conv.add_module(\"BN4\", nn.BatchNorm2d(64))\n",
    "        self.conv.add_module(\"Relu4\", nn.ReLU())\n",
    "        self.conv.add_module(\"Layer4MaxPool\", nn.MaxPool2d(2))\n",
    "                             \n",
    "        self.conv.add_module(\"Pad5\", nn.ConstantPad2d((0,1,0,1), 0))\n",
    "        self.conv.add_module(\"Conv5\", nn.Conv2d(64, 128, kernel_size=2))\n",
    "        self.conv.add_module(\"BN5\", nn.BatchNorm2d(128))\n",
    "        self.conv.add_module(\"Relu5\", nn.ReLU())\n",
    "        \n",
    "        self.conv.add_module(\"Pad6\", nn.ConstantPad2d((0,1,0,1), 0))\n",
    "        self.conv.add_module(\"Conv6\", nn.Conv2d(128, 128, kernel_size=2))\n",
    "        self.conv.add_module(\"BN6\", nn.BatchNorm2d(128))\n",
    "        self.conv.add_module(\"Relu6\", nn.ReLU())\n",
    "        self.conv.add_module(\"Layer6MaxPool\", nn.MaxPool2d(2))\n",
    "        \n",
    "        self.conv.add_module(\"Pad7\", nn.ConstantPad2d((0,1,0,1), 0))\n",
    "        self.conv.add_module(\"Conv7\", nn.Conv2d(128, 256, kernel_size=2))\n",
    "        self.conv.add_module(\"BN7\", nn.BatchNorm2d(256))\n",
    "        self.conv.add_module(\"Relu7\", nn.ReLU())\n",
    "        \n",
    "        self.conv.add_module(\"Pad8\", nn.ConstantPad2d((0,1,0,1), 0))\n",
    "        self.conv.add_module(\"Conv8\", nn.Conv2d(256, 256, kernel_size=2))\n",
    "        self.conv.add_module(\"BN8\", nn.BatchNorm2d(256))\n",
    "        self.conv.add_module(\"Relu8\", nn.ReLU())\n",
    "        \n",
    "        self.fc = nn.Sequential()\n",
    "        self.fc.add_module(\"FC1\", nn.Linear(4096, 1000))\n",
    "        self.fc.add_module(\"Relu9\", nn.ReLU())\n",
    "        self.fc.add_module(\"Dropout1\", nn.Dropout(0.5))\n",
    "        self.fc.add_module(\"FC2\", nn.Linear(1000, 100))\n",
    "        self.fc.add_module(\"Relu10\", nn.ReLU())\n",
    "        self.fc.add_module(\"Dropout1\", nn.Dropout(0.5))\n",
    "        self.fc.add_module(\"FC3\",nn.Linear(100, 2)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiClassClassifier()\n",
    "# model = VesselClassifier()\n",
    "model.cuda()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================\n",
    "# We may wish to load a previous model\n",
    "load_saved = False\n",
    "if load_saved:\n",
    "    saved_models = list(map(lambda x: os.path.splitext(x)[0], filter(lambda x: os.path.splitext(x)[1] == '.sav', os.listdir('.'))))\n",
    "    print(saved_models)\n",
    "    attempts = 0\n",
    "    while attempts < 3:\n",
    "        attempts += 1\n",
    "        model_name = input(\"Choose a saved model: \")\n",
    "        if model_name not in saved_models:\n",
    "            print(\"Not found. Try again\")\n",
    "            continue\n",
    "        else:\n",
    "            model.load_state_dict(torch.load(model_name+\".sav\"))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labelled_patches(img, truth):\n",
    "    img = np.dstack((img, truth))\n",
    "    patches = imgutil.extract_patches_2d(img, (32,32))\n",
    "    np.random.shuffle(patches)\n",
    "    positive_patches = []\n",
    "    negative_patches = []\n",
    "    positive_labels = []\n",
    "    for patch in patches:\n",
    "              \n",
    "        truth = patch[16,16,3]\n",
    "        patch = patch[:,:,:3]  \n",
    "        patch = np.rollaxis(patch,2,0)\n",
    "\n",
    "        if truth != 0:\n",
    "            positive_patches.append(torch.from_numpy(patch))\n",
    "            positive_labels.append(truth)\n",
    "        else:\n",
    "            negative_patches.append(torch.from_numpy(patch))\n",
    "            \n",
    "    return torch.stack(positive_patches), torch.stack(negative_patches), positive_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensors(images, features):\n",
    "    \n",
    "    patches = []\n",
    "    labels = []\n",
    "    \n",
    "    for image, feature in zip(images, features):\n",
    "        pos, neg, pos_labels = get_labelled_patches(image, feature)\n",
    "        neg = neg[:len(pos)*5,:,:]\n",
    "        patches.extend(pos)\n",
    "        patches.extend(neg)\n",
    "            \n",
    "        pos_l = torch.Tensor(pos_labels)\n",
    "        neg_l = torch.zeros(len(neg))\n",
    "        labels.extend(pos_l)\n",
    "        labels.extend(neg_l)\n",
    "    \n",
    "    image_tensor = torch.stack(patches).float()\n",
    "    label_tensor = torch.stack(labels)\n",
    "    return image_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_numpy_data_task1(source):\n",
    "\n",
    "    # train_path_truths = os.path.join(\"Data_Group_Component_Task_1\", \"Train\", \"masks_Hard_Exudates\")\n",
    "    train_path_images = os.path.join(\"Data_Group_Component_Task_1\", source, \"original_retinal_images\")\n",
    "\n",
    "    train_path_exudates = os.path.join(\"Data_Group_Component_Task_1\", source, \"masks_Hard_Exudates\")\n",
    "    train_path_soft_exudates = os.path.join(\"Data_Group_Component_Task_1\", source, \"masks_Soft_Exudates\")\n",
    "    train_path_haemorrhages = os.path.join(\"Data_Group_Component_Task_1\", source, \"masks_Haemorrhages\")\n",
    "    train_path_microaneurysms = os.path.join(\"Data_Group_Component_Task_1\", source, \"masks_Microaneurysms\")\n",
    "\n",
    "    train_image_names = os.listdir(train_path_images)\n",
    "\n",
    "    train_exudate_names = list(map(lambda x: os.path.join(train_path_exudates, x.split('.')[0] + '_EX.tif'), train_image_names))\n",
    "    train_haem_names = list(map(lambda x: os.path.join(train_path_haemorrhages, x.split('.')[0] + '_HE.tif'), train_image_names))\n",
    "    train_sfex_names = list(map(lambda x: os.path.join(train_path_soft_exudates, x.split('.')[0] + '_SE.tif'), train_image_names))\n",
    "    train_ma_names = list(map(lambda x: os.path.join(train_path_microaneurysms, x.split('.')[0] + '_MA.tif'), train_image_names))\n",
    "\n",
    "    images = list(map(\n",
    "        lambda x: cv2.resize(\n",
    "            cv2.imread(\n",
    "                os.path.join(train_path_images, x)\n",
    "            ), (256, 256)\n",
    "        ), train_image_names))\n",
    "\n",
    "    \n",
    "    features = []\n",
    "    for names in zip(train_exudate_names, train_haem_names, train_sfex_names, train_ma_names):\n",
    "        he, ha, se, ma =  names\n",
    "\n",
    "        he = cv2.imread(he)\n",
    "        if he is not None:\n",
    "            he = cv2.resize(he, (256,256))[:,:,2]\n",
    "        else:\n",
    "            he = np.zeros((256,256), dtype=np.uint8)\n",
    "\n",
    "        ha = cv2.imread(ha)\n",
    "        if ha is not None:\n",
    "            ha = cv2.resize(ha, (256,256))[:,:,2]\n",
    "        else:\n",
    "            ha = np.zeros((256,256), dtype=np.uint8)\n",
    "\n",
    "        se = cv2.imread(se)\n",
    "        if se is not None:\n",
    "            se = cv2.resize(se, (256,256))[:,:,2]\n",
    "        else:\n",
    "            se = np.zeros((256,256), dtype=np.uint8)\n",
    "\n",
    "        ma = cv2.imread(ma)\n",
    "        if ma is not None:\n",
    "            ma = cv2.resize(ma, (256,256))[:,:,2]\n",
    "        else:\n",
    "            ma = np.zeros((256,256), dtype=np.uint8)    \n",
    "\n",
    "        feature_map = (he != 0).astype(np.uint8)\n",
    "        feature_map[np.where(ha != 0)] = 2\n",
    "        feature_map[np.where(se != 0)] = 3\n",
    "        feature_map[np.where(ma != 0)] = 4\n",
    "\n",
    "        features.append(feature_map)\n",
    "    \n",
    "    return images, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_numpy_data_task2(source):\n",
    "    \n",
    "    def read_video(video_path):\n",
    "        video = cv2.VideoCapture(str(video_path))\n",
    "        while video.isOpened():\n",
    "            ok, frame = video.read()\n",
    "\n",
    "            if not ok:\n",
    "                break\n",
    "\n",
    "            yield frame\n",
    "        video.release()\n",
    "\n",
    "    if source == \"Train\":\n",
    "        source = \"Training\"\n",
    "    # train_path_truths = os.path.join(\"Data_Group_Component_Task_1\", \"Train\", \"masks_Hard_Exudates\")\n",
    "    train_path_images = os.path.join(\"Data_Group_Component_Task_2\", source, \"original_retinal_images\")\n",
    "\n",
    "    train_path_vessels = os.path.join(\"Data_Group_Component_Task_2\", source, \"blood_vessel_segmentation_masks\")\n",
    "   \n",
    "    train_image_names = os.listdir(train_path_images)\n",
    "\n",
    "    train_vessel_names = list(map(lambda x: os.path.join(train_path_vessels, x.split('_')[0] + '_manual1.gif'), train_image_names))\n",
    "\n",
    "    images = list(map(\n",
    "        lambda x: cv2.resize(\n",
    "            cv2.imread(\n",
    "                os.path.join(train_path_images, x)\n",
    "            ), (256, 256)\n",
    "        ), train_image_names))\n",
    "\n",
    "    images = list(map(normalise_image, images))\n",
    "    \n",
    "    features = []\n",
    "    for name in train_vessel_names:\n",
    "        print(name)\n",
    "        \n",
    "        vessels = list(read_video(name))[0]\n",
    "        \n",
    "        if vessels is not None:\n",
    "            vessels = cv2.resize(vessels, (256,256))[:,:,2]\n",
    "        else:\n",
    "            vessels = np.zeros((256,256), dtype=np.uint8)\n",
    "\n",
    "        feature_map = (vessels != 0).astype(np.uint8)\n",
    "\n",
    "        features.append(feature_map)\n",
    "    \n",
    "    return images, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_numpy_data = load_numpy_data_task1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list, label_list = load_numpy_data(\"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_tensor, label_tensor = create_tensors(image_list, label_list)\n",
    "\n",
    "mean = torch.mean(image_tensor, axis=tuple(range(image_tensor.ndim-1)))\n",
    "std = torch.std(image_tensor, axis=tuple(range(image_tensor.ndim-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the data into pytorch DataLoader for batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss:713.6724153272808 Trained in 57.71755814552307 seconds\n",
      "Epoch: 2 Loss:506.0491146296263 Trained in 57.03878211975098 seconds\n",
      "Epoch: 3 Loss:424.66163576580584 Trained in 61.10589146614075 seconds\n",
      "Epoch: 4 Loss:366.312396902591 Trained in 57.663920164108276 seconds\n",
      "Epoch: 5 Loss:326.84037521854043 Trained in 56.72777462005615 seconds\n",
      "Epoch: 6 Loss:287.71891102474183 Trained in 57.76373767852783 seconds\n",
      "Epoch: 7 Loss:253.99396940972656 Trained in 61.29642081260681 seconds\n",
      "Epoch: 8 Loss:224.2651601145044 Trained in 56.523176431655884 seconds\n",
      "Epoch: 9 Loss:196.0254759497475 Trained in 56.214316606521606 seconds\n",
      "Epoch: 10 Loss:170.1361532052979 Trained in 56.51357674598694 seconds\n",
      "Epoch: 11 Loss:143.75554694479797 Trained in 59.27753257751465 seconds\n",
      "Epoch: 12 Loss:128.34042917389888 Trained in 65.13123846054077 seconds\n",
      "Epoch: 13 Loss:117.96772166597657 Trained in 59.18282151222229 seconds\n",
      "Epoch: 14 Loss:99.64340712223202 Trained in 57.57897639274597 seconds\n",
      "Epoch: 15 Loss:96.5849818548013 Trained in 61.383140325546265 seconds\n",
      "Epoch: 16 Loss:81.82929446843627 Trained in 59.72114396095276 seconds\n",
      "Epoch: 17 Loss:75.98241369836614 Trained in 60.86075568199158 seconds\n",
      "Epoch: 18 Loss:68.071551157469 Trained in 57.895015478134155 seconds\n",
      "Epoch: 19 Loss:68.48381859020992 Trained in 60.763410568237305 seconds\n",
      "Epoch: 20 Loss:59.05432393711544 Trained in 58.78290677070618 seconds\n",
      "Epoch: 21 Loss:54.21742838382488 Trained in 58.9499831199646 seconds\n",
      "Epoch: 22 Loss:55.70453807181184 Trained in 66.47119069099426 seconds\n",
      "Epoch: 23 Loss:53.46599085596608 Trained in 65.91866946220398 seconds\n",
      "Epoch: 24 Loss:50.00808014307586 Trained in 64.03770065307617 seconds\n",
      "Epoch: 25 Loss:48.684754509359664 Trained in 69.00441479682922 seconds\n",
      "Epoch: 26 Loss:44.41877448082232 Trained in 63.62181329727173 seconds\n",
      "Epoch: 27 Loss:43.646012488643464 Trained in 64.12446880340576 seconds\n",
      "Epoch: 28 Loss:41.61564432535033 Trained in 64.35884022712708 seconds\n",
      "Epoch: 29 Loss:40.67611216077148 Trained in 69.13307094573975 seconds\n",
      "Epoch: 30 Loss:43.09139860295545 Trained in 66.34951543807983 seconds\n",
      "Epoch: 31 Loss:38.04414625870959 Trained in 64.47353529930115 seconds\n",
      "Epoch: 32 Loss:35.82831880873357 Trained in 65.02805185317993 seconds\n",
      "Epoch: 33 Loss:35.17955786897346 Trained in 66.30363988876343 seconds\n",
      "Epoch: 34 Loss:33.97683439698767 Trained in 63.663700580596924 seconds\n",
      "Epoch: 35 Loss:55.37476139500859 Trained in 64.58523535728455 seconds\n",
      "Epoch: 36 Loss:30.49495854710767 Trained in 64.96920895576477 seconds\n",
      "Epoch: 37 Loss:29.290675584854853 Trained in 69.31857371330261 seconds\n",
      "Epoch: 38 Loss:26.913177895473837 Trained in 66.48615145683289 seconds\n",
      "Epoch: 39 Loss:33.04521372619206 Trained in 64.07061266899109 seconds\n",
      "Epoch: 40 Loss:31.61170827624835 Trained in 64.87246823310852 seconds\n",
      "Epoch: 41 Loss:28.114322598939452 Trained in 67.84252429008484 seconds\n",
      "Epoch: 42 Loss:29.333565473447834 Trained in 67.39472103118896 seconds\n",
      "Epoch: 43 Loss:37.24992894049478 Trained in 64.14341640472412 seconds\n",
      "Epoch: 44 Loss:30.690357258718677 Trained in 63.783379793167114 seconds\n",
      "Epoch: 45 Loss:23.926230172855867 Trained in 64.09853839874268 seconds\n",
      "Epoch: 46 Loss:25.46616068289518 Trained in 64.77173686027527 seconds\n",
      "Epoch: 47 Loss:33.38436936255903 Trained in 65.34021615982056 seconds\n",
      "Epoch: 48 Loss:26.69608107404673 Trained in 67.82556891441345 seconds\n",
      "Epoch: 49 Loss:26.238376181276635 Trained in 65.22253084182739 seconds\n",
      "Epoch: 50 Loss:22.780638721257617 Trained in 65.48881912231445 seconds\n",
      "Epoch: 51 Loss:22.385283683339026 Trained in 64.08357810974121 seconds\n",
      "Epoch: 52 Loss:27.427904260457808 Trained in 64.06163573265076 seconds\n",
      "Epoch: 53 Loss:20.820731595180007 Trained in 69.46617984771729 seconds\n",
      "Epoch: 54 Loss:25.30460778275409 Trained in 68.15369057655334 seconds\n",
      "Epoch: 55 Loss:27.407035574508825 Trained in 66.82225227355957 seconds\n",
      "Epoch: 56 Loss:23.882579694715076 Trained in 63.67267632484436 seconds\n",
      "Epoch: 57 Loss:18.23558974177294 Trained in 66.00842952728271 seconds\n",
      "Epoch: 58 Loss:28.71617450832332 Trained in 64.81262707710266 seconds\n",
      "Epoch: 59 Loss:18.092562417860563 Trained in 66.5749135017395 seconds\n",
      "Epoch: 60 Loss:25.20699694143826 Trained in 67.49245882034302 seconds\n",
      "Epoch: 61 Loss:20.465005413020776 Trained in 64.880446434021 seconds\n",
      "Epoch: 62 Loss:22.478231827845093 Trained in 64.23816537857056 seconds\n",
      "Epoch: 63 Loss:20.98834755023995 Trained in 66.19991779327393 seconds\n",
      "Epoch: 64 Loss:20.734317858970428 Trained in 64.39175319671631 seconds\n",
      "Epoch: 65 Loss:20.080102323696337 Trained in 67.9183201789856 seconds\n",
      "Epoch: 66 Loss:22.124151745373524 Trained in 64.1703462600708 seconds\n",
      "Epoch: 67 Loss:19.266388458236406 Trained in 67.96020817756653 seconds\n",
      "Epoch: 68 Loss:17.206070492637366 Trained in 64.53636693954468 seconds\n",
      "Epoch: 69 Loss:21.73722592353988 Trained in 64.77672457695007 seconds\n",
      "Epoch: 70 Loss:18.476838835703205 Trained in 66.44725584983826 seconds\n",
      "Epoch: 71 Loss:16.993520929337592 Trained in 72.45518612861633 seconds\n",
      "Epoch: 72 Loss:26.274000586510496 Trained in 70.96417260169983 seconds\n",
      "Epoch: 73 Loss:21.637501463666126 Trained in 67.57623505592346 seconds\n",
      "Epoch: 74 Loss:16.13261266174976 Trained in 64.47652745246887 seconds\n",
      "Epoch: 75 Loss:18.580628441086866 Trained in 66.48814678192139 seconds\n",
      "Epoch: 76 Loss:24.268269236250717 Trained in 64.91236233711243 seconds\n",
      "Epoch: 77 Loss:18.047585777858075 Trained in 67.48048973083496 seconds\n",
      "Epoch: 78 Loss:14.72220295051126 Trained in 66.28070068359375 seconds\n",
      "Epoch: 79 Loss:19.691603149094647 Trained in 66.3624815940857 seconds\n",
      "Epoch: 80 Loss:15.304709884313866 Trained in 68.86478972434998 seconds\n",
      "Epoch: 81 Loss:36.48680121523834 Trained in 67.45655632019043 seconds\n",
      "Epoch: 82 Loss:12.331152770735788 Trained in 68.18959450721741 seconds\n",
      "Epoch: 83 Loss:16.302797531054054 Trained in 67.92630195617676 seconds\n",
      "Epoch: 84 Loss:23.687892789615855 Trained in 64.38177800178528 seconds\n",
      "Epoch: 85 Loss:13.792917375524368 Trained in 65.5496563911438 seconds\n",
      "Epoch: 86 Loss:19.132399939658697 Trained in 63.65971112251282 seconds\n",
      "Epoch: 87 Loss:16.260926293269705 Trained in 64.66103339195251 seconds\n",
      "Epoch: 88 Loss:22.393711559674973 Trained in 65.97651410102844 seconds\n",
      "Epoch: 89 Loss:15.092996804251044 Trained in 65.68629026412964 seconds\n",
      "Epoch: 90 Loss:17.52578488061529 Trained in 68.11280012130737 seconds\n",
      "Epoch: 91 Loss:14.349990453879217 Trained in 68.57057523727417 seconds\n",
      "Epoch: 92 Loss:19.014610684430345 Trained in 65.67133140563965 seconds\n",
      "Epoch: 93 Loss:18.15920403036354 Trained in 65.7241895198822 seconds\n",
      "Epoch: 94 Loss:17.280431361743055 Trained in 64.67000937461853 seconds\n",
      "Epoch: 95 Loss:16.676032163474474 Trained in 68.20754551887512 seconds\n",
      "Epoch: 96 Loss:14.227713901742938 Trained in 66.0922040939331 seconds\n",
      "Epoch: 97 Loss:19.402774375600643 Trained in 65.39108061790466 seconds\n",
      "Epoch: 98 Loss:10.96717104731469 Trained in 67.67896127700806 seconds\n",
      "Epoch: 99 Loss:15.047181263447698 Trained in 65.7840301990509 seconds\n",
      "Epoch: 100 Loss:17.678666169158383 Trained in 66.25676584243774 seconds\n",
      "Epoch: 1 Loss:540.1668883003294 Trained in 64.64308094978333 seconds\n",
      "Epoch: 2 Loss:352.7373608928174 Trained in 67.41267251968384 seconds\n",
      "Epoch: 3 Loss:277.58898046053946 Trained in 66.83521866798401 seconds\n",
      "Epoch: 4 Loss:226.13026191666722 Trained in 65.59553289413452 seconds\n",
      "Epoch: 5 Loss:180.30736104614334 Trained in 64.53138041496277 seconds\n",
      "Epoch: 6 Loss:154.87055245158263 Trained in 66.97783541679382 seconds\n",
      "Epoch: 7 Loss:117.3232176968595 Trained in 66.14805436134338 seconds\n",
      "Epoch: 8 Loss:96.64533288445091 Trained in 68.18560528755188 seconds\n",
      "Epoch: 9 Loss:87.35834635826177 Trained in 63.78138613700867 seconds\n",
      "Epoch: 10 Loss:74.3774752143072 Trained in 68.90368485450745 seconds\n",
      "Epoch: 11 Loss:60.696590915878915 Trained in 68.7959713935852 seconds\n",
      "Epoch: 12 Loss:63.53739200714608 Trained in 66.07724452018738 seconds\n",
      "Epoch: 13 Loss:53.321655791878584 Trained in 66.60184168815613 seconds\n",
      "Epoch: 14 Loss:52.5472583759838 Trained in 65.5496563911438 seconds\n",
      "Epoch: 15 Loss:46.878361521374245 Trained in 67.06061387062073 seconds\n",
      "Epoch: 16 Loss:41.59905430884464 Trained in 64.43464016914368 seconds\n",
      "Epoch: 17 Loss:40.61260003154348 Trained in 69.97083020210266 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 Loss:40.81916815043405 Trained in 69.70354461669922 seconds\n",
      "Epoch: 19 Loss:37.585002107343826 Trained in 69.71152377128601 seconds\n",
      "Epoch: 20 Loss:39.121547532418845 Trained in 67.84750938415527 seconds\n",
      "Epoch: 21 Loss:30.735269776054793 Trained in 64.03371143341064 seconds\n",
      "Epoch: 22 Loss:32.92275110141418 Trained in 69.32455945014954 seconds\n",
      "Epoch: 23 Loss:33.428624439865985 Trained in 66.21798014640808 seconds\n",
      "Epoch: 24 Loss:44.636184004233655 Trained in 64.51941156387329 seconds\n",
      "Epoch: 25 Loss:28.24809390806513 Trained in 65.06595015525818 seconds\n",
      "Epoch: 26 Loss:25.186901116719696 Trained in 65.1058440208435 seconds\n",
      "Epoch: 27 Loss:27.959434051499557 Trained in 66.98880648612976 seconds\n",
      "Epoch: 28 Loss:27.83032178459598 Trained in 64.1683509349823 seconds\n",
      "Epoch: 29 Loss:24.016852821137945 Trained in 65.02505993843079 seconds\n",
      "Epoch: 30 Loss:28.916332027465614 Trained in 65.38409876823425 seconds\n",
      "Epoch: 31 Loss:27.526303284802452 Trained in 69.79130983352661 seconds\n",
      "Epoch: 32 Loss:33.419316388054085 Trained in 69.93891549110413 seconds\n",
      "Epoch: 33 Loss:24.206327782928838 Trained in 66.74844932556152 seconds\n",
      "Epoch: 34 Loss:92.88280038314315 Trained in 64.06861901283264 seconds\n",
      "Epoch: 35 Loss:20.420449507733792 Trained in 66.95788908004761 seconds\n",
      "Epoch: 36 Loss:16.472549405372774 Trained in 65.4798424243927 seconds\n",
      "Epoch: 37 Loss:22.862918668829252 Trained in 65.99945306777954 seconds\n",
      "Epoch: 38 Loss:22.24805860927711 Trained in 70.08652114868164 seconds\n",
      "Epoch: 39 Loss:25.3630335710468 Trained in 64.49846887588501 seconds\n",
      "Epoch: 40 Loss:25.38805970749013 Trained in 65.5925407409668 seconds\n",
      "Epoch: 41 Loss:22.44112465839919 Trained in 67.36180877685547 seconds\n",
      "Epoch: 42 Loss:22.104447711761622 Trained in 65.08190822601318 seconds\n",
      "Epoch: 43 Loss:21.15371605908593 Trained in 65.10684132575989 seconds\n",
      "Epoch: 44 Loss:21.459556444145107 Trained in 64.88144326210022 seconds\n",
      "Epoch: 45 Loss:20.400133814563674 Trained in 67.76672625541687 seconds\n",
      "Epoch: 46 Loss:20.64872607965168 Trained in 64.2381649017334 seconds\n",
      "Epoch: 47 Loss:19.543347425057902 Trained in 64.47453236579895 seconds\n",
      "Epoch: 48 Loss:21.304775004512294 Trained in 67.0725839138031 seconds\n",
      "Epoch: 49 Loss:25.57025110402435 Trained in 67.80761575698853 seconds\n",
      "Epoch: 50 Loss:18.018082309797137 Trained in 68.3581440448761 seconds\n",
      "Epoch: 51 Loss:17.86211879995176 Trained in 64.06861805915833 seconds\n",
      "Epoch: 52 Loss:32.38055613242159 Trained in 66.38542056083679 seconds\n",
      "Epoch: 53 Loss:13.9560706650322 Trained in 64.76974272727966 seconds\n",
      "Epoch: 54 Loss:23.624490641643035 Trained in 65.02805137634277 seconds\n",
      "Epoch: 55 Loss:22.91765573655988 Trained in 68.9326057434082 seconds\n",
      "Epoch: 56 Loss:16.895674702693213 Trained in 63.902063846588135 seconds\n",
      "Epoch: 57 Loss:35.18452722319512 Trained in 67.8963782787323 seconds\n",
      "Epoch: 58 Loss:13.1027195410367 Trained in 67.12843441963196 seconds\n",
      "Epoch: 59 Loss:16.633641206702677 Trained in 64.34787034988403 seconds\n",
      "Epoch: 60 Loss:19.003015871356723 Trained in 67.62809586524963 seconds\n",
      "Epoch: 61 Loss:17.64138808582277 Trained in 66.80529761314392 seconds\n",
      "Epoch: 62 Loss:41.63281162380659 Trained in 64.0546555519104 seconds\n",
      "Epoch: 63 Loss:13.864682526753768 Trained in 65.53968262672424 seconds\n",
      "Epoch: 64 Loss:17.204994047904677 Trained in 64.25312423706055 seconds\n",
      "Epoch: 65 Loss:19.795059394986538 Trained in 67.2102153301239 seconds\n",
      "Epoch: 66 Loss:17.116183761939283 Trained in 69.9548716545105 seconds\n",
      "Epoch: 67 Loss:14.698940099138127 Trained in 70.09050965309143 seconds\n",
      "Epoch: 68 Loss:17.605718644047215 Trained in 72.67659163475037 seconds\n",
      "Epoch: 69 Loss:21.456722045845268 Trained in 69.64989376068115 seconds\n",
      "Epoch: 70 Loss:15.069835487107134 Trained in 68.03101897239685 seconds\n",
      "Epoch: 71 Loss:24.190127208112244 Trained in 75.2271203994751 seconds\n",
      "Epoch: 72 Loss:21.444902034468043 Trained in 71.66703796386719 seconds\n",
      "Epoch: 73 Loss:14.376884240709387 Trained in 72.32647657394409 seconds\n",
      "Epoch: 74 Loss:19.490836037568904 Trained in 66.8597571849823 seconds\n",
      "Epoch: 75 Loss:14.736136077978642 Trained in 65.85622358322144 seconds\n",
      "Epoch: 76 Loss:17.73572368704839 Trained in 66.53476214408875 seconds\n",
      "Epoch: 77 Loss:14.188431923638952 Trained in 65.23872447013855 seconds\n",
      "Epoch: 78 Loss:18.06264904087638 Trained in 63.14455270767212 seconds\n",
      "Epoch: 79 Loss:26.51941314224267 Trained in 66.26675844192505 seconds\n",
      "Epoch: 80 Loss:22.122927482144803 Trained in 64.27167820930481 seconds\n",
      "Epoch: 81 Loss:12.98646051390216 Trained in 67.01682662963867 seconds\n",
      "Epoch: 82 Loss:15.544828920766236 Trained in 64.99665379524231 seconds\n",
      "Epoch: 83 Loss:13.661899337775935 Trained in 66.02373147010803 seconds\n",
      "Epoch: 84 Loss:27.75506179131267 Trained in 63.64763617515564 seconds\n",
      "Epoch: 85 Loss:15.648232341340531 Trained in 63.77565026283264 seconds\n",
      "Epoch: 86 Loss:18.38230491795875 Trained in 65.3625431060791 seconds\n",
      "Epoch: 87 Loss:18.884569442383018 Trained in 66.14306879043579 seconds\n",
      "Epoch: 88 Loss:13.098912043293467 Trained in 69.39536881446838 seconds\n",
      "Epoch: 89 Loss:21.95249896288601 Trained in 63.09422564506531 seconds\n",
      "Epoch: 90 Loss:13.456875924501276 Trained in 68.75208973884583 seconds\n",
      "Epoch: 91 Loss:15.49988951652918 Trained in 69.68559288978577 seconds\n",
      "Epoch: 92 Loss:15.902115701037133 Trained in 67.23514938354492 seconds\n",
      "Epoch: 93 Loss:20.342974587528943 Trained in 65.8717942237854 seconds\n",
      "Epoch: 94 Loss:19.27556560614741 Trained in 67.94026112556458 seconds\n",
      "Epoch: 95 Loss:14.587844424025008 Trained in 67.182288646698 seconds\n",
      "Epoch: 96 Loss:18.138783995815402 Trained in 65.74513339996338 seconds\n",
      "Epoch: 97 Loss:12.578789956946991 Trained in 64.57925128936768 seconds\n",
      "Epoch: 98 Loss:17.27522079236627 Trained in 64.17333722114563 seconds\n",
      "Epoch: 99 Loss:12.299996306567891 Trained in 64.33689975738525 seconds\n",
      "Epoch: 100 Loss:14.840904457141733 Trained in 67.0785665512085 seconds\n",
      "Epoch: 1 Loss:596.6600081175566 Trained in 67.17032027244568 seconds\n",
      "Epoch: 2 Loss:414.42027595825493 Trained in 67.34684944152832 seconds\n",
      "Epoch: 3 Loss:340.9597055502236 Trained in 65.0061104297638 seconds\n",
      "Epoch: 4 Loss:284.04612150322646 Trained in 64.58324122428894 seconds\n",
      "Epoch: 5 Loss:248.8168065911159 Trained in 64.84753561019897 seconds\n",
      "Epoch: 6 Loss:200.2202202877961 Trained in 65.03503346443176 seconds\n",
      "Epoch: 7 Loss:174.58918852475472 Trained in 64.09554624557495 seconds\n",
      "Epoch: 8 Loss:141.4834474772215 Trained in 68.33221435546875 seconds\n",
      "Epoch: 9 Loss:125.32119203649927 Trained in 64.59321427345276 seconds\n",
      "Epoch: 10 Loss:107.49198930890998 Trained in 69.00940155982971 seconds\n",
      "Epoch: 11 Loss:95.59410438258783 Trained in 64.26808476448059 seconds\n",
      "Epoch: 12 Loss:106.29127362577128 Trained in 69.12209963798523 seconds\n",
      "Epoch: 13 Loss:95.05429946587537 Trained in 69.6696343421936 seconds\n",
      "Epoch: 14 Loss:66.11324036120277 Trained in 65.9851770401001 seconds\n",
      "Epoch: 15 Loss:57.98115792873432 Trained in 67.71214652061462 seconds\n",
      "Epoch: 16 Loss:56.18562820893203 Trained in 66.8685998916626 seconds\n",
      "Epoch: 17 Loss:55.94913919325336 Trained in 73.18124151229858 seconds\n",
      "Epoch: 18 Loss:57.280227003710024 Trained in 70.21717166900635 seconds\n",
      "Epoch: 19 Loss:50.41901450858677 Trained in 76.54125499725342 seconds\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "losses_per_dataset = []\n",
    "for dataset in [(0,100000),(100000,200000),(200000,300000),(300000,424976)]:\n",
    "    train_dataset = utils.TensorDataset(image_tensor[dataset[0]:dataset[1]], label_tensor[dataset[0]:dataset[1]])\n",
    "    train_dataloader = utils.DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "    losses_per_epoch = []\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(0, epochs):\n",
    "        t0 = time.time()\n",
    "        losses_per_batch = []\n",
    "\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            patches, labels = data\n",
    "\n",
    "            # clear gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass\n",
    "            output = model(patches.cuda().float())\n",
    "\n",
    "            # calculate batch loss\n",
    "            loss = criterion(output, labels.cuda().long())\n",
    "            # compute \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses_per_batch.append(loss.item())\n",
    "\n",
    "        t1 = time.time()\n",
    "        losses_per_epoch.append(sum(losses_per_batch))\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"Epoch: {0} Loss:{1} Trained in {2} seconds\".format(epoch+1, sum(losses_per_batch), t1-t0))\n",
    "    \n",
    "    losses_per_dataset.append(losses_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train the data for **epochs** on mini-batches of **batch_size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"5class_normalised_1streak\" + \".sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = input(\"Name the model \")\n",
    "torch.save(model.state_dict(), model_name + \".sav\")\n",
    "print(f\"Saved as {model_name}.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recolour(image):\n",
    "    colours = np.array([\n",
    "        [0,0,0],\n",
    "        [0,255,0],\n",
    "        [0,0,255],\n",
    "        [255,0,0],\n",
    "        [255,0,255],\n",
    "    ])\n",
    "    \n",
    "    colour_vector = np.take(colours, image.flatten(), axis=0)\n",
    "    colour_vector = np.reshape(colour_vector, (image.shape[0], image.shape[1], 3))\n",
    "    \n",
    "    return colour_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test, feature_test = load_numpy_data(\"Test\")\n",
    "\n",
    "# image_test = np.array(image_test)\n",
    "\n",
    "# image_test_mean = np.mean(image_test, axis=tuple(range(image_test.ndim-1)))\n",
    "# image_test_std = np.std(image_test, axis=tuple(range(image_test.ndim-1)))\n",
    "\n",
    "# image_test = image_test - image_test_mean\n",
    "# image_test = image_test / image_test_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "\n",
    "\n",
    "def test(num, epochs, task, name):\n",
    "    model.eval()\n",
    "    image, truth = list(zip(image_test, feature_test))[num]\n",
    "    patches = imgutil.extract_patches_2d(image, (32,32))\n",
    "    rolled_patches = [torch.Tensor(np.rollaxis(patch,2,0)) for patch in patches]\n",
    "    rolled_patches_tensor = torch.stack(rolled_patches)\n",
    "    image_patches_dataset = utils.TensorDataset(rolled_patches_tensor)\n",
    "    image_loader = utils.DataLoader(image_patches_dataset, batch_size=225)\n",
    "\n",
    "    generated_mask = []\n",
    "\n",
    "    for i, image_patch_ in enumerate(image_loader):\n",
    "        img_patch = image_patch_[0]\n",
    "        test_output = model(img_patch.cuda())\n",
    "        labels = torch.argmax(test_output,1)# convert one hot to index/pixel form\n",
    "        generated_mask.append(labels.cpu().data.numpy())\n",
    "\n",
    "    generated_mask = np.array(generated_mask)\n",
    "    \n",
    "    coloured = recolour(generated_mask)\n",
    "    \n",
    "\n",
    "    \n",
    "    coloured_truth = recolour(truth[16:16+225,16:16+225])\n",
    "\n",
    "    side_by_side = np.hstack((coloured_truth, coloured, image[16:16+225,16:16+225]))\n",
    "    cv2.imwrite(f\"outputs/{task}/{name}/test{num}_{name}_{epochs}.jpg\", side_by_side)\n",
    "    \n",
    "    with open(f'outputs/{task}/{name}/test{num}_{name}_{epochs}.sav', 'wb') as file:\n",
    "        pkl.dump({\n",
    "            'pred': generated_mask,\n",
    "            'truth': truth,\n",
    "            'sideBySide': side_by_side,\n",
    "            'trainingLoss': losses_per_dataset,\n",
    "        }, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(image_test)):\n",
    "    test(i, \"1streak10epochs\", \"task1\", \"focalLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = []\n",
    "\n",
    "for dataset in losses_per_dataset:\n",
    "    for epoch in dataset:\n",
    "        print(epoch)\n",
    "        learning.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(learning)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.savefig('125epochs_1streak.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
